Salary Data using Naive Bayes
import pandas as pd
import numpy as np

######### Salary Data Set ########################
salary_train = pd.read_csv("E:\\Assignment\\Naive Bayes\\SalaryData_Train.csv")
salary_test = pd.read_csv("E:\\Assignment\\Naive Bayes\\SalaryData_Test.csv")
string_columns=["workclass","education","maritalstatus","occupation","relationship","race","sex","native"]

from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

from sklearn import preprocessing
number = preprocessing.LabelEncoder()
for i in string_columns:
    salary_train[i] = number.fit_transform(salary_train[i])
    salary_test[i] = number.fit_transform(salary_test[i])
colnames = salary_train.columns
len(colnames[0:13])
trainX = salary_train[colnames[0:13]]
trainY = salary_train[colnames[13]]
testX  = salary_test[colnames[0:13]]
testY  = salary_test[colnames[13]]

sgnb = GaussianNB()
smnb = MultinomialNB()
spred_gnb = sgnb.fit(trainX,trainY).predict(testX)
confusion_matrix(testY,spred_gnb)

array([[10759,   601],
       [ 2491,  1209]], dtype=int64)

print ("Accuracy",(10759+1209)/(10759+601+2491+1209)) 

Accuracy 0.7946879150066402

spred_mnb = smnb.fit(trainX,trainY).predict(testX)
confusion_matrix(testY,spred_mnb)

array([[10891,   469],
       [ 2920,   780]], dtype=int64)

print("Accuracy",(10891+780)/(10891+780+2920+780))
Accuracy 0.7592869689675362


SMS using Naive Bayes

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer

# Loading the data set

sms = pd.read_csv("E:\\Assignment\\Naive Bayes\\sms_raw_NB.csv",encoding = "ISO-8859-1")
# cleaning data 
import re
stop_words = []
with open("E:\\Assignment\Text Mining\\stop.txt") as f:
    stop_words = f.read()
stop_words

# splitting the entire string by giving separator as "\n" to get list of 
# all stop words
stop_words = stop_words.split("\n")
stop_words

def cleaning_text(i):
    i = re.sub("[^A-Za-z" "]+"," ",i).lower()
    i = re.sub("[0-9" "]+"," ",i)
    w = []
    for word in i.split(" "):
        if len(word)>3:
            w.append(word)
    return (" ".join(w))

sms.text = sms.text.apply(cleaning_text)

# removing empty rows 
sms.shape
sms= sms.loc[sms.text != " ",:]

# CountVectorizer
# Convert a collection of text documents to a matrix of token counts

# TfidfTransformer
# Transform a count matrix to a normalized tf or tf-idf representation

# creating a matrix of token counts for the entire text document 

def split_into_words(i):
    return [word for word in i.split(" ")]


# splitting data into train and test data sets 
from sklearn.model_selection import train_test_split

sms_train,sms_test = train_test_split(sms,test_size=0.3)


# Preparing email texts into word count matrix format 
sms_bow = CountVectorizer(analyzer=split_into_words).fit(sms.text)

# For all messages
all_emails_matrix = sms_bow.transform(sms.text)
all_emails_matrix.shape 
(5559, 6661)

# For training messages
train_emails_matrix = sms_bow.transform(sms_train.text)
train_emails_matrix.shape
(3891, 6661)



# For testing messages
test_emails_matrix = sms_bow.transform(sms_test.text)
test_emails_matrix.shape 
(1668, 6661)

####### Without TFIDF matrices ########################
# Preparing a naive bayes model on training data set 

from sklearn.naive_bayes import MultinomialNB as MB
from sklearn.naive_bayes import GaussianNB as GB

# Multinomial Naive Bayes
classifier_mb = MB()
classifier_mb.fit(train_emails_matrix,sms_train.type)
train_pred_m = classifier_mb.predict(train_emails_matrix)
accuracy_train_m = np.mean(train_pred_m==sms_train.type) 
accuracy_train_m
0.9824239808153477

test_pred_m = classifier_mb.predict(test_emails_matrix)
accuracy_test_m = np.mean(test_pred_m==sms_test.type) 
accuracy_test_m
0.9700239808153477






# Gaussian Naive Bayes 
classifier_gb = GB()
classifier_gb.fit(train_emails_matrix.toarray(),sms_train.type.values) # we need to convert tfidf into array format which is compatible for gaussian naive bayes
train_pred_g = classifier_gb.predict(train_emails_matrix.toarray())
accuracy_train_g = np.mean(train_pred_g==sms_train.type) # 90%
accuracy_train_g
0.9020817270624518

test_pred_g = classifier_gb.predict(test_emails_matrix.toarray())
accuracy_test_g = np.mean(test_pred_g==sms_test.type) # 83%
accuracy_test_g
0.8339328537170264


# Learning Term weighting and normalizing on entire emails
tfidf_transformer = TfidfTransformer().fit(all_emails_matrix)

# Preparing TFIDF for train emails
train_tfidf = tfidf_transformer.transform(train_emails_matrix)
print(train_tfidf.shape) 

# Preparing TFIDF for test emails
test_tfidf = tfidf_transformer.transform(test_emails_matrix)
print(test_tfidf.shape)

(3891, 6661)
(1668, 6661)


# Preparing a naive bayes model on training data set 

from sklearn.naive_bayes import MultinomialNB as MB
from sklearn.naive_bayes import GaussianNB as GB

# Multinomial Naive Bayes
classifier_mb = MB()
classifier_mb.fit(train_tfidf,sms_train.type)
train_pred_m = classifier_mb.predict(train_tfidf)
accuracy_train_m = np.mean(train_pred_m==sms_train.type) # 96%
print(accuracy_train_m)
test_pred_m = classifier_mb.predict(test_tfidf)
accuracy_test_m = np.mean(test_pred_m==sms_test.type) # 95%
print(accuracy_test_m)

0.9645335389360061
0.960431654676259

# Gaussian Naive Bayes 
classifier_gb = GB()
classifier_gb.fit(train_tfidf.toarray(),sms_train.type.values) # we need to convert tfidf into array format which is compatible for gaussian naive bayes
train_pred_g = classifier_gb.predict(train_tfidf.toarray())
accuracy_train_g = np.mean(train_pred_g==sms_train.type)
print(accuracy_train_g)
test_pred_g = classifier_gb.predict(test_tfidf.toarray())
accuracy_test_g = np.mean(test_pred_g==sms_test.type) 
print(accuracy_test_g)
0.9020817270624518
0.8339328537170264


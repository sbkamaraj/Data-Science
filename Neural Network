Concrete using NN
concrete<-read.csv(file.choose())
View(concrete)
summary(concrete)
# custom normalization function
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}
# apply normalization to entire data frame
concrete_norm <- as.data.frame(lapply(concrete, normalize))
summary(concrete_norm)
# create training and test data
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]

## Training a model on the data ----
# train the neuralnet model
install.packages("neuralnet")
library(neuralnet)

# simple ANN with only a single hidden neuron
concrete_model <- neuralnet(formula = strength ~ cement + slag +
                              ash + water + superplastic + 
                              coarseagg + fineagg + age,
                            data = concrete_train)

?neuralnet
# visualize the network topology
plot(concrete_model)

 
 
  results_model <- NULL
results_model <- compute(concrete_model, concrete_test[1:8])
# obtain predicted strength values
str(results_model)
predicted_strength <- results_model$net.result
# examine the correlation between predicted and actual values
cor(predicted_strength, concrete_test$strength)
0.8063657

?neuralnet
## Improving model performance ----
# a more complex neural network topology with 10 hidden neurons
concrete_model2 <- neuralnet(strength ~ cement + slag +
                               ash + water + superplastic + 
                               coarseagg + fineagg + age,
                             data = concrete_train, hidden = 10)

# plot the network
plot(concrete_model2)
 
# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
0.9373157




Concrete using NN

forest <- read.csv(file.choose())
View(forest)
forest$size_category <- factor(forest$size_category, level=c("small","large"),
                               labels = c(1,0))
normalize<-function(x){
  return ( (x-min(x))/(max(x)-min(x)))
}
forest$temp = normalize(forest$temp)
forest$RH   = normalize(forest$RH)
forest$wind = normalize(forest$wind)
forest$rain = normalize(forest$rain)

attach(forest)
View(forest)
# Data Partition 
set.seed(123)
ind <- sample(2, nrow(forest), replace = TRUE, prob = c(0.7,0.3))
forest_train <- forest[ind==1,]
forest_test  <- forest[ind==2,]
View(forest_train)
View(forest_test)

library(neuralnet)

# simple ANN with only a single hidden neuron
forest_model <- neuralnet(formula = size_category ~ temp+RH+wind+rain,
                            data = forest_train)
plot(forest_model)
 

results_model <- NULL
results_model <- compute(forest_model, forest_test[7:10])
results_model
# obtain predicted strength values
str(results_model)
predicted_category <- results_model$net.result
View(predicted_category)
pred <- ifelse(predicted_category>.5,1,0)
# examine the correlation between predicted and actual values
cor(predicted_category, as.numeric(forest_test$size_category))

Startup using NN
startup <- read.csv(file.choose())
View(startup)
startup$State <- factor(startup$State, level = c("New York","California","Florida"), 
                        labels = c(1,2,3))
library(caTools)
set.seed(123)
split = sample.split(startup$Profit, SplitRatio = 0.8)
training_set = subset(startup, split == TRUE)
test_set = subset(startup, split == FALSE)
library(neuralnet)

# simple ANN with only a single hidden neuron
startup_model <- neuralnet(formula = Profit ~ R.D.Spend+Administration+Marketing.Spend,
                            data = training_set, hidden = 10,stepmax=1e7)
plot(startup_model)
results_model <- NULL
results_model <- compute(startup_model, test_set[1:3])
# obtain predicted strength values
str(results_model)
predicted <- results_model$net.result
View(results_model)
# examine the correlation between predicted and actual values
cor(predicted, test_set$Profit)
